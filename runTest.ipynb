{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce2e217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\msi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\msi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "!pip install opencv-python\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84f81808",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir= r'C:\\Users\\MSI\\Desktop\\pfa jupyter\\Data' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca8b2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MSI\\\\Desktop\\\\pfa jupyter\\\\Data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc341e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i='NonViolence'\n",
    "source = r'C:\\Users\\MSI\\Desktop\\pfa jupyter\\Real Life Violence Dataset' +'\\\\' +i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5f8093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MSI\\\\Desktop\\\\pfa jupyter\\\\Real Life Violence Dataset\\\\NonViolence'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7516a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c9ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rootdir= 'Data' \n",
    "#path of the original folder\n",
    "classes = ['Violence','NonViolence']\n",
    "for i in classes:\n",
    "  os.makedirs(rootdir +'\\\\train\\\\'+ i)\n",
    "  os.makedirs(rootdir +'\\\\test\\\\' + i)\n",
    "  source = r'C:\\Users\\MSI\\Desktop\\pfa jupyter\\Real Life Violence Dataset' +'\\\\' +i\n",
    "  allFileNames = os.listdir(source)\n",
    "  np.random.shuffle(allFileNames)\n",
    "  test_ratio = 0.25\n",
    "  train_FileNames, test_FileNames = np.split(np.array(allFileNames),[int(len(allFileNames)* (1 - test_ratio))])\n",
    "  train_FileNames = [source+'\\\\'+ name for name in train_FileNames.tolist()]\n",
    "  test_FileNames = [source+'\\\\' + name for name in test_FileNames.tolist()]\n",
    "  for name in train_FileNames:\n",
    "    shutil.copy(name, rootdir +'\\\\train\\\\' + i)\n",
    "  for name in test_FileNames:\n",
    "    shutil.copy(name, rootdir +'\\\\test\\\\' + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f263337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img_remove_black(img, x_crop, y_crop, y, x):\n",
    "    x_start = x_crop\n",
    "    x_end = x - x_crop\n",
    "    y_start = y_crop\n",
    "    y_end = y-y_crop\n",
    "    frame = img[y_start:y_end, x_start:x_end, :]\n",
    "    # return img[44:244,16:344, :]\n",
    "    return frame\n",
    "\n",
    "\n",
    "def uniform_sampling(video, target_frames=64):\n",
    "    # get total frames of input video and calculate sampling interval\n",
    "    len_frames = video.shape[0]\n",
    "    interval = int(np.ceil(len_frames/target_frames))\n",
    "    # init empty list for sampled video and\n",
    "    sampled_video = []\n",
    "    for i in range(0, len_frames, interval):\n",
    "        sampled_video.append(video[i])\n",
    "    # calculate numer of padded frames and fix it\n",
    "    num_pad = target_frames - len(sampled_video)\n",
    "    padding = []\n",
    "    if num_pad > 0:\n",
    "        for i in range(-num_pad, 0):\n",
    "            try:\n",
    "                padding.append(video[i])\n",
    "            except:\n",
    "                padding.append(video[0])\n",
    "        sampled_video += padding\n",
    "    # get sampled video\n",
    "    return np.array(sampled_video)\n",
    "\n",
    "\n",
    "def Video2Npy(file_path, resize=320, crop_x_y=None, target_frames=None):\n",
    "    \"\"\"Load video and tansfer it into .npy format\n",
    "    Args:\n",
    "        file_path: the path of video file\n",
    "        resize: the target resolution of output video\n",
    "        crop_x_y: black boundary cropping\n",
    "        target_frames:\n",
    "    Returns:\n",
    "        frames: gray-scale video\n",
    "        flows: magnitude video of optical flows \n",
    "    \"\"\"\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    # Get number of frames\n",
    "    len_frames = int(cap.get(7))\n",
    "    frames = []\n",
    "    try:\n",
    "        for i in range(len_frames):\n",
    "            _, x_ = cap.read()\n",
    "            if crop_x_y:\n",
    "                frame = crop_img_remove_black(\n",
    "                    x_, crop_x_y[0], crop_x_y[1], x_.shape[0], x_.shape[1])\n",
    "            else:\n",
    "                frame = x_\n",
    "            frame = cv2.resize(frame, (resize,resize), interpolation=cv2.INTER_AREA)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = np.reshape(frame, (resize, resize, 3))\n",
    "            frames.append(frame)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", file_path, len_frames)\n",
    "        print(e)\n",
    "    finally:\n",
    "        frames = np.array(frames)\n",
    "        cap.release()\n",
    "    frames = uniform_sampling(frames, target_frames=target_frames)\n",
    "    return frames\n",
    "\n",
    "\n",
    "def Save2Npy(file_dir, save_dir, crop_x_y=None, target_frames=None, frame_size=320):\n",
    "    \"\"\"Transfer all the videos and save them into specified directory\n",
    "    Args:\n",
    "        file_dir: source folder of target videos\n",
    "        save_dir: destination folder of output .npy files\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    # List the files\n",
    "    videos = os.listdir(file_dir)\n",
    "    for v in tqdm(videos):\n",
    "        # Split video name\n",
    "        video_name = v.split('.')[0]\n",
    "        # Get src\n",
    "        video_path = os.path.join(file_dir, v)\n",
    "        # Get dest\n",
    "        save_path = os.path.join(save_dir, video_name+'.npy')\n",
    "        # Load and preprocess video\n",
    "        data = Video2Npy(file_path=video_path, resize=frame_size,\n",
    "                         crop_x_y=crop_x_y, target_frames=target_frames)\n",
    "        if target_frames:\n",
    "            assert (data.shape == (target_frames,\n",
    "                                   frame_size, frame_size, 3))\n",
    "        os.remove(video_path)\n",
    "        data = np.uint8(data)\n",
    "        # Save as .npy file\n",
    "        np.save(save_path, data)\n",
    "    return None\n",
    "\n",
    "\n",
    "def convert_dataset_to_npy(src, dest, crop_x_y=None, target_frames=None, frame_size=320):\n",
    "    #if not os.path.isdir(dest):\n",
    "     #   os.path.makedirs(dest)\n",
    "    for dir_ in ['train', 'test']:\n",
    "        for cat_ in ['Violence', 'NonViolence']:\n",
    "            path1 = os.path.join(src, dir_, cat_)\n",
    "            path2 = os.path.join(dest, dir_, cat_)\n",
    "            Save2Npy(file_dir=path1, save_dir=path2, crop_x_y=crop_x_y,\n",
    "                     target_frames=target_frames, frame_size=frame_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b939fdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\MSI\\\\Desktop\\\\pfa jupyter\\\\Data'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61426f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest=r'C:\\\\Users\\\\MSI\\\\Desktop\\\\pfa jupyter\\\\Data npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0f6bdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 749/749 [05:46<00:00,  2.16it/s]  \n",
      "100%|██████████| 750/750 [02:19<00:00,  5.39it/s]\n",
      "100%|██████████| 250/250 [01:32<00:00,  2.71it/s]\n",
      "100%|██████████| 250/250 [01:21<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "convert_dataset_to_npy(rootdir, dest, crop_x_y=None, target_frames=32, frame_size=320)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bdb363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=r'C:\\\\Users\\\\MSI\\\\Desktop\\\\pfa jupyter\\\\train.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b1089c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8a4865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\msi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pydot) (3.0.4)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6cc5629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\msi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f7dbd31",
   "metadata": {},
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3041f871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\MSI\\Desktop\\pfa jupyter\\train.py\", line 13, in <module>\n",
      "    import models\n",
      "  File \"C:\\Users\\MSI\\Desktop\\pfa jupyter\\models.py\", line 1, in <module>\n",
      "    from tensorflow.keras import backend as K\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py\", line 10, in <module>\n",
      "    from keras import __version__\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\__init__.py\", line 25, in <module>\n",
      "    from keras import models\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\models.py\", line 20, in <module>\n",
      "    from keras import metrics as metrics_module\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\metrics.py\", line 26, in <module>\n",
      "    from keras import activations\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\activations.py\", line 20, in <module>\n",
      "    from keras.layers import advanced_activations\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\__init__.py\", line 31, in <module>\n",
      "    from keras.layers.preprocessing.image_preprocessing import CenterCrop\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\preprocessing\\image_preprocessing.py\", line 24, in <module>\n",
      "    from keras.preprocessing import image as image_preprocessing\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\preprocessing\\__init__.py\", line 26, in <module>\n",
      "    from keras.utils import all_utils as utils\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\all_utils.py\", line 34, in <module>\n",
      "    from keras.utils.multi_gpu_utils import multi_gpu_model\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\multi_gpu_utils.py\", line 20, in <module>\n",
      "    from keras.layers.core import Lambda\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\core\\__init__.py\", line 20, in <module>\n",
      "    from keras.layers.core.dropout import Dropout\n",
      "  File \"C:\\Users\\MSI\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\layers\\core\\dropout.py\", line 26, in <module>\n",
      "    class Dropout(base_layer.BaseRandomLayer):\n",
      "AttributeError: module 'keras.engine.base_layer' has no attribute 'BaseRandomLayer'\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataset Data --vidLen 32 --batchSize 4 --numEpochs 2 --mode only_differences  --lstmType conv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc94cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ae363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
